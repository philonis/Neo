import streamlit as st
import json
import time
import uuid
from llm_client import LLMClient
from core import SkillManager, ReActAgent, TaskPlanner, VectorMemory
from tools.soul_skill import SoulSkill

st.set_page_config(
    page_title="Neo æ™ºèƒ½åŠ©æ‰‹", 
    page_icon="ğŸ§ ", 
    layout="centered",
    initial_sidebar_state="expanded"
)

@st.cache_resource
def init_resources():
    client = LLMClient()
    skill_manager = SkillManager()
    memory = VectorMemory()
    soul = SoulSkill()
    agent = ReActAgent(client, skill_manager, memory)
    planner = TaskPlanner(client, skill_manager)
    return client, skill_manager, memory, soul, agent, planner

client, skill_manager, memory, soul, agent, planner = init_resources()

if "messages" not in st.session_state:
    st.session_state.messages = []

if "interaction_count" not in st.session_state:
    st.session_state.interaction_count = 0

if "show_trace" not in st.session_state:
    st.session_state.show_trace = False

with st.sidebar:
    st.header("âš™ï¸ è®¾ç½®")
    st.session_state.show_trace = st.checkbox("æ˜¾ç¤ºæ‰§è¡Œè½¨è¿¹", value=False)
    
    st.divider()
    st.header("ğŸ”§ å·²åŠ è½½æŠ€èƒ½")
    for skill_name in skill_manager.list_skills():
        info = skill_manager.get_skill_info(skill_name)
        if info:
            desc = info["schema"].get("function", {}).get("description", "")[:40]
            st.caption(f"**{skill_name}**: {desc}...")
    
    st.divider()
    st.header("ğŸ“Š è®°å¿†ç»Ÿè®¡")
    stats = memory.get_stats()
    st.metric("çŸ­æœŸè®°å¿†", stats["short_term_count"])
    st.metric("é•¿æœŸè®°å¿†", stats["long_term_count"])
    st.metric("ç´¢å¼•å…³é”®è¯", stats["index_keywords"])

st.title("ğŸ§  Neo æ™ºèƒ½åŠ©æ‰‹")
st.caption("åŸºäº ReAct æ¶æ„ | åŸç”Ÿ Function Calling | æ™ºèƒ½è®°å¿†ç³»ç»Ÿ")

for message in st.session_state.messages:
    if message["role"] in ["user", "assistant"]:
        with st.chat_message(message["role"]):
            st.markdown(message["content"])
            
            if message["role"] == "assistant" and "trace" in message:
                with st.expander("ğŸ“‹ æ‰§è¡Œè½¨è¿¹", expanded=False):
                    for item in message["trace"]:
                        st.write(f"**æ­¥éª¤ {item['iteration']}**: è°ƒç”¨ `{item['tool']}`")
                        if "error" in item.get("result", {}):
                            st.error(f"âŒ {item['result']['error']}")
                        else:
                            st.success("âœ… æ‰§è¡ŒæˆåŠŸ")

if prompt := st.chat_input("è¯·è¾“å…¥æŒ‡ä»¤..."):
    st.chat_message("user").markdown(prompt)
    st.session_state.messages.append({"role": "user", "content": prompt})
    
    with st.chat_message("assistant"):
        progress_placeholder = st.empty()
        trace_placeholder = st.empty()
        
        def on_progress(stage: str, message: str):
            icons = {
                "thinking": "ğŸ§ ",
                "action": "âš¡",
                "observation": "ğŸ‘ï¸"
            }
            icon = icons.get(stage, "â–¶ï¸")
            progress_placeholder.info(f"{icon} {message}")
        
        progress_placeholder.info("ğŸ§  æ­£åœ¨æ€è€ƒ...")
        
        context = [m for m in st.session_state.messages[:-1] if m["role"] in ["user", "assistant"]]
        
        result = agent.run(prompt, context=context, on_progress=on_progress)
        
        progress_placeholder.empty()
        
        if result["success"]:
            final_response = result["response"]
            st.markdown(final_response)
            
            if st.session_state.show_trace and result.get("trace"):
                with st.expander("ğŸ“‹ æ‰§è¡Œè½¨è¿¹", expanded=False):
                    for item in result["trace"]:
                        st.write(f"**æ­¥éª¤ {item['iteration']}**: è°ƒç”¨ `{item['tool']}`")
                        st.json(item["args"])
                        if "error" in item.get("result", {}):
                            st.error(f"âŒ {item['result']['error']}")
                        else:
                            final_reply = "ä»£ç ç”Ÿæˆå¤±è´¥ã€‚"
                            should_replan = False
                            break

                    # æƒ…å†µ B: æ™®é€šèŠå¤©
                    elif tool_name == "chat":
                        temp_msgs = st.session_state.messages + [{"role": "system", "content": f"å·¥å…·æ‰§è¡Œæ—¥å¿—: {json.dumps(execution_log)}"}]
                        response = client.chat(temp_msgs)
                        final_reply = response["choices"][0]["message"]["content"]
                        # ä»»åŠ¡å®Œæˆï¼Œæ— éœ€é‡è§„åˆ’
                        should_replan = False 

                    # æƒ…å†µ C: è°ƒç”¨å·¥å…·
                    elif tool_name in skill_manager.skills:
                        func = skill_manager.get_skill(tool_name)
                        result = func(tool_args)
                        execution_log.append({"step": step_desc, "result": result})
                        
                        # å°†ç»“æœæ³¨å…¥å†å²
                        st.session_state.messages.append({
                            "role": "system",
                            "content": f"å·¥å…· [{tool_name}] æ‰§è¡Œç»“æœ: {json.dumps(result, ensure_ascii=False)}"
                        })
                        
                        # å¦‚æœæ˜¯æœ€åä¸€æ­¥ï¼Œç”Ÿæˆæ€»ç»“
                        if step_item == plan_data["plan"][-1]:
                             summary_prompt = "æ ¹æ®ä¸Šè¿°å·¥å…·æ‰§è¡Œç»“æœï¼Œå›å¤ç”¨æˆ·ã€‚"
                             temp_msgs = st.session_state.messages + [{"role": "user", "content": summary_prompt}]
                             res = client.chat(temp_msgs)
                             final_reply = res["choices"][0]["message"]["content"]
                             should_replan = False
                    else:
                        placeholder.error(f"âŒ æœªçŸ¥å·¥å…·: {tool_name}")
                        should_replan = False
                        break

                # å¦‚æœä¸éœ€è¦é‡è§„åˆ’ï¼ˆä»»åŠ¡å®Œæˆæˆ–å¤±è´¥ï¼‰ï¼Œé€€å‡º while å¾ªç¯
                if not should_replan:
                    break
            
            # å¾ªç¯ç»“æŸï¼Œæ˜¾ç¤ºæœ€ç»ˆç»“æœ
            if final_reply:
                placeholder.markdown(final_reply)
                st.session_state.messages.append({"role": "assistant", "content": final_reply})
            else:
                # å›é€€æœºåˆ¶ï¼šå¦‚æœæŠ€èƒ½æ‰§è¡Œå¤±è´¥ï¼Œä½¿ç”¨èŠå¤©æ¨¡å¼ç”Ÿæˆå›å¤
                placeholder.markdown("ğŸ¤” æ­£åœ¨ç”Ÿæˆå›å¤...")
                fallback_response = client.chat(st.session_state.messages)
                if fallback_response:
                    final_reply = fallback_response["choices"][0]["message"]["content"]
                    placeholder.markdown(final_reply)
                    st.session_state.messages.append({"role": "assistant", "content": final_reply})
                else:
                    placeholder.markdown("æŠ±æ­‰ï¼Œæˆ‘é‡åˆ°äº†ä¸€äº›é—®é¢˜ï¼Œè¯·ç¨åå†è¯•ã€‚")

    # --- 5. è®°å¿†æ›´æ–° ---
    if final_reply:
        memory.record_interaction(prompt, final_reply, client)
        st.session_state.interaction_count += 1
        
        if st.session_state.interaction_count % 10 == 0:
            with st.spinner("ğŸ§˜ æ­£åœ¨å‹ç¼©è®°å¿†..."):
                memory.compress(client)
            
            recent_chat = memory.get_context_for_prompt("æœ€è¿‘çš„å¯¹è¯")
            soul.reflect_and_evolve(recent_chat, client)
