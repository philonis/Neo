import streamlit as st
import json
import time
import re
from llm_client import LLMClient
from tools.memory_skill import PersonalMemorySkill
from tools.soul_skill import SoulSkill
from core.skill_manager import SkillManager

# --- 1. é¡µé¢é…ç½® ---
st.set_page_config(page_title="Neo æ™ºèƒ½åŠ©æ‰‹", page_icon="ğŸ§ ", layout="centered")

# --- 2. æ ¸å¿ƒèµ„æºåˆå§‹åŒ– (å…¨å±€å•ä¾‹) ---
@st.cache_resource
def init_resources():
    client = LLMClient()
    memory = PersonalMemorySkill()
    soul = SoulSkill()
    skill_manager = SkillManager()
    return client, memory, soul, skill_manager

client, memory, soul, skill_manager = init_resources()

# --- 3. è¾…åŠ©å‡½æ•° ---

def build_context_messages(full_system_prompt, history_messages, current_input):
    """æ„å»ºå¸¦æœ‰å†å²ä¸Šä¸‹æ–‡çš„å®Œæ•´æ¶ˆæ¯åˆ—è¡¨"""
    messages = [{"role": "system", "content": full_system_prompt}]
    # å–æœ€è¿‘ 5 è½®å†å² (10æ¡æ¶ˆæ¯)
    recent_history = history_messages[-6:] if len(history_messages) > 6 else history_messages[:-1]
    if recent_history:
        messages.extend(recent_history)
    messages.append({"role": "user", "content": current_input})
    return messages

def classify_intent(user_input, tool_names, history_context):
    """è·¯ç”±å™¨ï¼šåˆ¤æ–­ç”¨æˆ·æ„å›¾"""
    prompt = f"""
    å†å²å¯¹è¯æ‘˜è¦: {history_context[-1] if history_context else "æ— "}
    å½“å‰ç”¨æˆ·è¾“å…¥: "{user_input}"
    å¯ç”¨åŠŸèƒ½: {tool_names}
    
    åˆ¤æ–­æ„å›¾ï¼š
    1. å¦‚æœæ˜¯ç®€å•çš„é—®å€™ã€é—²èŠã€å¸¸è¯†é—®é¢˜ -> å›å¤ "CHAT"
    2. å¦‚æœæ¶‰åŠæ–‡ä»¶æ“ä½œã€æ•°æ®æŸ¥è¯¢ã€ç³»ç»Ÿè®¾ç½®ã€æˆ–è€…éœ€è¦è°ƒç”¨å·¥å…· -> å›å¤ "TASK"
    
    åªèƒ½å›å¤ CHAT æˆ– TASKã€‚
    """
    result = client.simple_chat(prompt)
    return "TASK" if "TASK" in result else "CHAT"

def extract_json_from_text(text):
    """å¥å£®çš„ JSON æå–é€»è¾‘"""
    try:
        # 1. æ¸…æ´— XML æ ‡ç­¾
        clean_content = re.sub(r'<[^>]+>', '', text).strip()
        
        # 2. æå– JSON
        json_str = clean_content
        if "```json" in json_str:
            json_str = json_str.split("```json")[1].split("```")[0].strip()
        elif "```" in json_str:
            json_str = json_str.split("```")[1].split("```")[0].strip()
            
        if json_str.startswith("{") and "plan" in json_str:
            return json.loads(json_str)
        else:
            return None
    except:
        return None

# --- 4. Session State åˆå§‹åŒ– ---

# è·å–å½“å‰å¯ç”¨å·¥å…·
available_tools = skill_manager.get_all_tools_schema()
tool_names = [t['function']['name'] for t in available_tools]

# æ„å»ºç³»ç»Ÿæç¤º (æ³¨å…¥äººæ ¼å’Œè®°å¿†)
if "system_prompt" not in st.session_state:
    base_system_prompt = (
        "ä½ æ˜¯ä¸€ä¸ªé«˜çº§æœ¬åœ°åŠ©æ‰‹ Neoã€‚ä½ å…·å¤‡è§„åˆ’èƒ½åŠ›ã€‚\n"
        "é‡è¦è§„åˆ™ï¼šå½“ä½ éœ€è¦å›ç­”å…³äºç”¨æˆ·æ•°æ®çš„é—®é¢˜æ—¶ï¼Œ**å¿…é¡»å…ˆè°ƒç”¨å·¥å…·è¯»å–æ•°æ®**ï¼Œä¸è¦é¢„è®¾è‡ªå·±ä¸çŸ¥é“ã€‚"
    )
    soul_context = soul.load_soul()
    memory_context = memory.load_context()
    st.session_state.system_prompt = base_system_prompt + soul_context + memory_context

# åˆå§‹åŒ–æ¶ˆæ¯å†å²
if "messages" not in st.session_state:
    st.session_state.messages = [{"role": "system", "content": st.session_state.system_prompt}]

# åˆå§‹åŒ–äº¤äº’è®¡æ•°å™¨
if "interaction_count" not in st.session_state:
    st.session_state.interaction_count = 0

# --- 5. ç•Œé¢å¸ƒå±€ ---

st.title("ğŸ§  Neo è§„åˆ’å¼åŠ©æ‰‹")
st.caption(f"å·²åŠ è½½æŠ€èƒ½: `{'`, `'.join(tool_names)}` | å…·å¤‡è‡ªæˆ‘è¿›åŒ–èƒ½åŠ›")

# æ˜¾ç¤ºå†å²èŠå¤©è®°å½•
for message in st.session_state.messages:
    if message["role"] in ["user", "assistant"]:
        with st.chat_message(message["role"]):
            st.markdown(message["content"])

# --- 6. ä¸»é€»è¾‘å¤„ç† ---

if prompt := st.chat_input("è¯·è¾“å…¥æŒ‡ä»¤..."):
    # 1. æ˜¾ç¤ºç”¨æˆ·æ¶ˆæ¯
    st.chat_message("user").markdown(prompt)
    st.session_state.messages.append({"role": "user", "content": prompt})

    # 2. æ„å›¾è·¯ç”±
    with st.status("ğŸ§ æ­£åœ¨ç†è§£æ„å›¾...", expanded=False) as status:
        intent = classify_intent(prompt, tool_names, st.session_state.messages)
        status.update(label=f"æ„å›¾è¯†åˆ«: {'ğŸš€ ä»»åŠ¡æ¨¡å¼' if intent == 'TASK' else 'ğŸ’¬ é—²èŠæ¨¡å¼'}", state="complete")

    final_reply = ""
    
    # --- åˆ†æ”¯ Aï¼šé—²èŠæ¨¡å¼ ---
    if intent == "CHAT":
        with st.chat_message("assistant"):
            response = client.chat(st.session_state.messages)
            if response:
                final_reply = response["choices"][0]["message"]["content"]
                st.markdown(final_reply)
            else:
                final_reply = "æŠ±æ­‰ï¼Œæˆ‘èµ°ç¥äº†..."
                st.error(final_reply)
            
            st.session_state.messages.append({"role": "assistant", "content": final_reply})

    # --- åˆ†æ”¯ Bï¼šä»»åŠ¡æ¨¡å¼ ---
    else:
        with st.chat_message("assistant"):
            placeholder = st.empty()
            placeholder.markdown("ğŸ§  æ­£åœ¨è§„åˆ’ä»»åŠ¡è·¯å¾„...")

            # 1. æ„å»ºè§„åˆ’è¯·æ±‚
            plan_messages = build_context_messages(st.session_state.system_prompt, st.session_state.messages, prompt)
            plan_directive = {
                "role": "system", 
                "content": f"""
                å½“å‰å¯ç”¨æŠ€èƒ½: {tool_names}
                
                # æ ¸å¿ƒèº«ä»½çº¦æŸ
                ä½ æ˜¯ä¸€ä¸ªä»»åŠ¡è§„åˆ’è€…ï¼Œä½ æœ¬äºº **ä¸èƒ½** æ‰§è¡Œä»»ä½•ä»£ç æˆ–è®¿é—®ç½‘ç»œã€‚
                ä½ åªèƒ½é€šè¿‡è°ƒç”¨ "å¯ç”¨æŠ€èƒ½" åˆ—è¡¨ä¸­çš„å·¥å…·æ¥å®Œæˆä»»åŠ¡ã€‚
                
                # ä¸¥ç¦è¡Œä¸º
                1. ä¸¥ç¦è¾“å‡º XML æ ‡ç­¾ (å¦‚ <minimax:tool_call>)ã€‚
                2. ä¸¥ç¦è¾“å‡ºä»£ç å— (å¦‚ ```python æˆ– curl)ã€‚
                3. ä¸¥ç¦å‡è£…å·²ç»æ‰§è¡Œäº†ä»»åŠ¡ã€‚
                
                # å¿…é¡»æ‰§è¡Œ
                ä½ å¿…é¡»è¾“å‡ºä¸€ä¸ªæ ‡å‡†çš„ JSON å¯¹è±¡æ¥æè¿°è®¡åˆ’ã€‚
                å¦‚æœç°æœ‰å·¥å…·æ— æ³•å®Œæˆä»»åŠ¡ï¼Œè¯·åŠ¡å¿…ä½¿ç”¨ "need_new_skill" å·¥å…·è¯·æ±‚æ–°èƒ½åŠ›ã€‚
                """
            }
            plan_messages.append(plan_directive)
            
            # 2. è·å–è§„åˆ’å“åº”
            plan_response = client.chat(plan_messages)
            
            if not plan_response:
                final_reply = "è§„åˆ’å¤±è´¥ï¼Œè¯·æ£€æŸ¥ç½‘ç»œã€‚"
                st.error(final_reply)
            else:
                raw_content = plan_response["choices"][0]["message"]["content"]
                plan_data = extract_json_from_text(raw_content)
                
                # 3. å¤„ç†è§„åˆ’è§£æå¤±è´¥ (è‡ªåŠ¨è½¬ä¸ºæŠ€èƒ½è¯·æ±‚)
                if not plan_data:
                    placeholder.markdown("âš ï¸ æ¨¡å‹æœªèƒ½ç”Ÿæˆæœ‰æ•ˆè®¡åˆ’ï¼Œæ­£åœ¨å°è¯•è‡ªåŠ¨æ„å»ºè§£å†³æ–¹æ¡ˆ...")
                    plan_data = {
                        "plan": [{
                            "step": "åˆ†æéœ€æ±‚å¹¶å®‰è£…å¿…è¦å·¥å…·", 
                            "tool": "need_new_skill", 
                            "args": {"description": f"ä¸ºäº†å®Œæˆç”¨æˆ·ä»»åŠ¡: '{prompt}'ï¼Œéœ€è¦å®‰è£…ç›¸å…³åŠŸèƒ½æ¨¡å—ã€‚"}
                        }]
                    }

                # 4. æ‰§è¡Œæ­¥éª¤
                execution_log = []
                for step_item in plan_data.get("plan", []):
                    step_desc = step_item.get("step", "")
                    tool_name = step_item.get("tool")
                    tool_args = step_item.get("args", {})

                    placeholder.markdown(f"â¡ï¸ **æ‰§è¡Œæ­¥éª¤**: {step_desc}")
                    time.sleep(0.5) # ç¨å¾®åœé¡¿ä¸€ä¸‹ï¼Œè®©ç”¨æˆ·çœ‹åˆ°è¿›åº¦

                    # æƒ…å†µ A: ç¼ºå¤±æŠ€èƒ½ -> è‡ªåŠ¨ç”Ÿæˆ
                    if tool_name == "need_new_skill":
                        missing_desc = tool_args.get("description", "æœªçŸ¥åŠŸèƒ½")
                        placeholder.markdown(f"ğŸ› ï¸ **æŠ€èƒ½ç¼ºå¤±**: {missing_desc} \n\n â³ æ­£åœ¨è‡ªåŠ¨ç¼–å†™æ–°æŠ€èƒ½...")
                        
                        new_skill_name = f"auto_skill_{int(time.time())}"
                        code_prompt = f"ç¼–å†™ Python è„šæœ¬å®ç°: {missing_desc}ã€‚è¦æ±‚ï¼šåŒ…å« run å‡½æ•°å’Œ get_tool_definition å‡½æ•°ã€‚å¿…é¡»è¿”å›æ ‡å‡† OpenAI Schemaã€‚åªè¾“å‡ºä»£ç ã€‚"
                        
                        # å†™ä»£ç ä¹Ÿéœ€è¦ä¸Šä¸‹æ–‡
                        code_context = build_context_messages(st.session_state.system_prompt, st.session_state.messages, code_prompt)
                        code_response = client.chat(code_context)
                        
                        if code_response:
                            code_content = code_response["choices"][0]["message"]["content"]
                            code_content = code_content.replace("```python", "").replace("```", "")
                            
                            # ä¿å­˜å¹¶åŠ è½½
                            filepath = skill_manager.create_skill_file(new_skill_name, code_content)
                            
                            # æ›´æ–°å½“å‰ä¼šè¯çš„å·¥å…·åˆ—è¡¨ (æ³¨æ„ï¼šè¿™é‡Œæ›´æ–°çš„æ˜¯å±€éƒ¨å˜é‡ï¼Œä¸‹æ¬¡è¿è¡Œä¼šè‡ªåŠ¨ä»ç¼“å­˜è¯»å–æ–°çŠ¶æ€)
                            available_tools = skill_manager.get_all_tools_schema()
                            tool_names = [t['function']['name'] for t in available_tools]
                            
                            final_reply = f"âœ… æ–°æŠ€èƒ½å·²ç”Ÿæˆå¹¶åŠ è½½ (`{new_skill_name}`)ã€‚è¯·**é‡æ–°å‘é€æŒ‡ä»¤**ä»¥ä½¿ç”¨å®ƒã€‚"
                            placeholder.markdown(final_reply)
                            
                            st.session_state.messages.append({"role": "assistant", "content": final_reply})
                            # ä»»åŠ¡æš‚åœï¼Œç­‰å¾…ç”¨æˆ·é‡è¯•
                            break 
                        else:
                            final_reply = "ä»£ç ç”Ÿæˆå¤±è´¥ã€‚"
                            placeholder.error(final_reply)
                            break

                    # æƒ…å†µ B: æ™®é€šèŠå¤©
                    elif tool_name == "chat":
                        temp_msgs = st.session_state.messages + [{"role": "system", "content": f"å·¥å…·æ‰§è¡Œæ—¥å¿—: {json.dumps(execution_log)}"}]
                        response = client.chat(temp_msgs)
                        final_reply = response["choices"][0]["message"]["content"]
                        placeholder.markdown(final_reply)
                        st.session_state.messages.append({"role": "assistant", "content": final_reply})

                    # æƒ…å†µ C: è°ƒç”¨å·¥å…·
                    elif tool_name in skill_manager.skills:
                        func = skill_manager.get_skill(tool_name)
                        result = func(tool_args)
                        execution_log.append({"step": step_desc, "result": result})
                        
                        # å°†ç»“æœæ³¨å…¥å†å²
                        st.session_state.messages.append({
                            "role": "system",
                            "content": f"å·¥å…· [{tool_name}] æ‰§è¡Œç»“æœ: {json.dumps(result, ensure_ascii=False)}"
                        })
                        
                        # å¦‚æœæ˜¯æœ€åä¸€æ­¥ï¼Œç”Ÿæˆæ€»ç»“
                        if step_item == plan_data["plan"][-1]:
                             summary_prompt = "æ ¹æ®ä¸Šè¿°å·¥å…·æ‰§è¡Œç»“æœï¼Œå›å¤ç”¨æˆ·ã€‚"
                             temp_msgs = st.session_state.messages + [{"role": "user", "content": summary_prompt}]
                             res = client.chat(temp_msgs)
                             final_reply = res["choices"][0]["message"]["content"]
                             placeholder.markdown(final_reply)
                             st.session_state.messages.append({"role": "assistant", "content": final_reply})
                    else:
                        placeholder.error(f"âŒ æœªçŸ¥å·¥å…·: {tool_name}")

    # --- 5. è®°å¿†æ›´æ–° ---
    if final_reply:
        # è®°å½•åˆ°å¤–éƒ¨æ–‡ä»¶
        memory.record_interaction(prompt, final_reply, client)
        
        # æ›´æ–°çµé­‚
        st.session_state.interaction_count += 1
        if st.session_state.interaction_count % 10 == 0:
            recent_chat = memory._read_file(memory.active_file)
            soul.reflect_and_evolve(recent_chat, client)
