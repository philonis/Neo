import streamlit as st
import json
from llm_client import LLMClient
from core import SkillManager, ReActAgent, TaskPlanner, VectorMemory
from tools.soul_skill import SoulSkill

st.set_page_config(
    page_title="Neo æ™ºèƒ½åŠ©æ‰‹", 
    page_icon="ğŸ§ ", 
    layout="centered",
    initial_sidebar_state="expanded"
)

@st.cache_resource
def init_resources():
    client = LLMClient()
    skill_manager = SkillManager()
    memory = VectorMemory()
    soul = SoulSkill()
    agent = ReActAgent(client, skill_manager, memory)
    planner = TaskPlanner(client, skill_manager)
    return client, skill_manager, memory, soul, agent, planner

client, skill_manager, memory, soul, agent, planner = init_resources()

if "messages" not in st.session_state:
    st.session_state.messages = []

if "interaction_count" not in st.session_state:
    st.session_state.interaction_count = 0

if "show_trace" not in st.session_state:
    st.session_state.show_trace = False

with st.sidebar:
    st.header("âš™ï¸ è®¾ç½®")
    st.session_state.show_trace = st.checkbox("æ˜¾ç¤ºæ‰§è¡Œè½¨è¿¹", value=False)
    
    st.divider()
    st.header("ğŸ”§ å·²åŠ è½½æŠ€èƒ½")
    for skill_name in skill_manager.list_skills():
        info = skill_manager.get_skill_info(skill_name)
        if info:
            desc = info["schema"].get("function", {}).get("description", "")[:40]
            st.caption(f"**{skill_name}**: {desc}...")
    
    st.divider()
    st.header("ğŸ“Š è®°å¿†ç»Ÿè®¡")
    stats = memory.get_stats()
    st.metric("çŸ­æœŸè®°å¿†", stats["short_term_count"])
    st.metric("é•¿æœŸè®°å¿†", stats["long_term_count"])
    st.metric("ç´¢å¼•å…³é”®è¯", stats["index_keywords"])

st.title("ğŸ§  Neo æ™ºèƒ½åŠ©æ‰‹")
st.caption("åŸºäº ReAct æ¶æ„ | åŸç”Ÿ Function Calling | æ™ºèƒ½è®°å¿†ç³»ç»Ÿ")

for message in st.session_state.messages:
    if message["role"] in ["user", "assistant"]:
        with st.chat_message(message["role"]):
            st.markdown(message["content"])
            
            if message["role"] == "assistant" and "trace" in message:
                with st.expander("ğŸ“‹ æ‰§è¡Œè½¨è¿¹", expanded=False):
                    for item in message["trace"]:
                        st.write(f"**æ­¥éª¤ {item['iteration']}**: è°ƒç”¨ `{item['tool']}`")
                        if "error" in item.get("result", {}):
                            st.error(f"âŒ {item['result']['error']}")
                        else:
                            st.success("âœ… æ‰§è¡ŒæˆåŠŸ")

if prompt := st.chat_input("è¯·è¾“å…¥æŒ‡ä»¤..."):
    st.chat_message("user").markdown(prompt)
    st.session_state.messages.append({"role": "user", "content": prompt})
    
    with st.chat_message("assistant"):
        progress_placeholder = st.empty()
        
        def on_progress(stage: str, message: str):
            icons = {
                "thinking": "ğŸ§ ",
                "action": "âš¡",
                "observation": "ğŸ‘ï¸"
            }
            icon = icons.get(stage, "â–¶ï¸")
            progress_placeholder.info(f"{icon} {message}")
        
        progress_placeholder.info("ğŸ§  æ­£åœ¨æ€è€ƒ...")
        
        context = [m for m in st.session_state.messages[:-1] if m["role"] in ["user", "assistant"]]
        
        result = agent.run(prompt, context=context, on_progress=on_progress)
        
        progress_placeholder.empty()
        
        if result["success"]:
            final_response = result["response"]
            st.markdown(final_response)
            
            if st.session_state.show_trace and result.get("trace"):
                with st.expander("ğŸ“‹ æ‰§è¡Œè½¨è¿¹", expanded=False):
                    for item in result["trace"]:
                        st.write(f"**æ­¥éª¤ {item['iteration']}**: è°ƒç”¨ `{item['tool']}`")
                        st.json(item["args"])
                        if "error" in item.get("result", {}):
                            st.error(f"âŒ {item['result']['error']}")
                        else:
                            st.success("âœ… æ‰§è¡ŒæˆåŠŸ")
                            with st.expander("æŸ¥çœ‹ç»“æœ"):
                                st.json(item["result"])
        else:
            final_response = f"æŠ±æ­‰ï¼Œä»»åŠ¡æ‰§è¡Œé‡åˆ°é—®é¢˜: {result['response']}"
            st.error(final_response)
        
        message_entry = {
            "role": "assistant", 
            "content": final_response
        }
        if result.get("trace"):
            message_entry["trace"] = result["trace"]
        
        st.session_state.messages.append(message_entry)
        
        memory.add_interaction(
            user_input=prompt,
            assistant_response=final_response,
            tool_calls=[{"name": t["tool"], "args": t["args"]} for t in result.get("trace", [])]
        )
        
        st.session_state.interaction_count += 1
        
        if st.session_state.interaction_count % 10 == 0:
            with st.spinner("ğŸ§˜ æ­£åœ¨å‹ç¼©è®°å¿†..."):
                memory.compress(client)
            
            recent_chat = memory.get_context_for_prompt("æœ€è¿‘çš„å¯¹è¯")
            soul.reflect_and_evolve(recent_chat, client)
